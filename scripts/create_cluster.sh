#!/usr/bin/env bash
# Script optimisÃ© pour le projet PageRank Wikipedia
# CrÃ©e 3 clusters Dataproc avec configurations comparables

set -euo pipefail

# ============================================
# CONFIGURATION
# ============================================

# Charger les variables d'environnement si .env existe
if [ -f ".env" ]; then
  source .env
fi

# Variables principales
PROJECT_ID="${PROJECT_ID:-YOUR_PROJECT_ID}"
REGION="${REGION:-europe-west1}"
ZONE="${ZONE:-}"  # Laissez vide pour auto-zone
IMAGE_VERSION="${IMAGE_VERSION:-2.1-debian11}"
BUCKET_NAME="${BUCKET_NAME:-pagerank-wikipedia-${PROJECT_ID}}"

# SÃ©curitÃ©
NO_EXTERNAL_IP="${NO_EXTERNAL_IP:-false}"
SUBNET="${SUBNET:-}"

# ============================================
# VALIDATION
# ============================================

if [ "$PROJECT_ID" = "YOUR_PROJECT_ID" ]; then
  echo "âŒ Erreur: Veuillez configurer PROJECT_ID dans .env ou en variable d'environnement"
  echo "   Exemple: export PROJECT_ID=mon-projet-gcp"
  exit 1
fi

echo "ğŸ”§ Configuration:"
echo "   Project ID: $PROJECT_ID"
echo "   Region: $REGION"
echo "   Bucket: $BUCKET_NAME"
echo ""

# ============================================
# FONCTION: CrÃ©er un cluster
# ============================================

create_cluster() {
  local cluster_name=$1
  local num_workers=$2
  local worker_machine_type=$3
  local master_machine_type=$4
  
  echo "ğŸ“¦ CrÃ©ation du cluster: $cluster_name"
  echo "   Workers: $num_workers x $worker_machine_type"
  echo "   Master: 1 x $master_machine_type"
  
  # Construire les arguments optionnels
  local zone_arg=""
  [ -n "$ZONE" ] && zone_arg="--zone=$ZONE"
  
  local subnet_arg=""
  [ -n "$SUBNET" ] && subnet_arg="--subnet=$SUBNET"
  
  local no_address_arg=""
  [ "$NO_EXTERNAL_IP" = true ] && no_address_arg="--no-address"
  
  # CrÃ©er le cluster
  gcloud dataproc clusters create "$cluster_name" \
    --project="$PROJECT_ID" \
    --region="$REGION" \
    $zone_arg \
    $subnet_arg \
    --master-machine-type="$master_machine_type" \
    --worker-machine-type="$worker_machine_type" \
    --num-workers="$num_workers" \
    --image-version="$IMAGE_VERSION" \
    --bucket="$BUCKET_NAME" \
    --enable-component-gateway \
    --properties="spark:spark.executor.memory=6g,spark:spark.driver.memory=4g,spark:spark.default.parallelism=$((num_workers * 4 * 2)),spark:spark.sql.shuffle.partitions=$((num_workers * 4 * 2))" \
    $no_address_arg
  
  if [ $? -eq 0 ]; then
    echo "   âœ… Cluster $cluster_name crÃ©Ã© avec succÃ¨s"
  else
    echo "   âŒ Erreur lors de la crÃ©ation de $cluster_name"
    return 1
  fi
  echo ""
}

# ============================================
# FONCTION: CrÃ©er le bucket GCS
# ============================================

create_bucket() {
  echo "CrÃ©ation du bucket GCS: $BUCKET_NAME"
  
  # VÃ©rifier si le bucket existe dÃ©jÃ 
  if gsutil ls -b "gs://$BUCKET_NAME" &>/dev/null; then
    echo "Le bucket existe dÃ©jÃ "
  else
    gsutil mb -p "$PROJECT_ID" -l "$REGION" "gs://$BUCKET_NAME"
    echo "   âœ… Bucket crÃ©Ã© avec succÃ¨s"
  fi
  echo ""
}

# ============================================
# FONCTION: Afficher les informations
# ============================================

show_info() {
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "âœ… TOUS LES CLUSTERS SONT CRÃ‰Ã‰S"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo ""
  echo "RÃ©sumÃ© des ressources:"
  echo ""
  echo "Cluster 1: pagerank-2w"
  echo "   â””â”€ 2 workers  n1-standard-8 (8 vCPU, 30 GB) = 16 vCPU"
  echo "   â””â”€ 1 master  n1-standard-4 (4 vCPU, 15 GB) = 4 vCPU"
  echo "   â””â”€ TOTAL: 20 vCPU, 75 GB RAM"
  echo ""
  echo "Cluster 2: pagerank-4w"
  echo "   â””â”€ 4 workers  n1-standard-4 (4 vCPU, 15 GB) = 16 vCPU"
  echo "   â””â”€ 1 master   n1-standard-4 (4 vCPU, 15 GB) = 4 vCPU"
  echo "   â””â”€ TOTAL: 20 vCPU, 75 GB RAM"
  echo ""
  echo "Cluster 3: pagerank-6w"
  echo "   â””â”€ 6 workers  n1-standard-4 (4 vCPU, 15 GB) = 24 vCPU"
  echo "   â””â”€ 1 master   n1-standard-4 (4 vCPU, 15 GB) = 4 vCPU"
  echo "   â””â”€ TOTAL: 28 vCPU, 105 GB RAM"
  echo ""
  echo "ğŸ“¦ Bucket GCS: gs://$BUCKET_NAME"
  echo ""
  echo "ğŸ”— Liens utiles:"
  echo "   â€¢ Console GCP: https://console.cloud.google.com/dataproc/clusters?project=$PROJECT_ID"
  echo "   â€¢ Bucket GCS:  https://console.cloud.google.com/storage/browser/$BUCKET_NAME?project=$PROJECT_ID"
  echo ""
  echo "ğŸ’¡ Prochaines Ã©tapes:"
  echo "   1. TÃ©lÃ©charger les donnÃ©es Wikipedia"
  echo "   2. Uploader vers GCS: gsutil cp data.bz2 gs://$BUCKET_NAME/"
  echo "   3. Lancer les jobs PageRank sur chaque cluster"
  echo ""
  echo "ğŸ—‘ï¸  Pour supprimer les clusters:"
  echo "   ./destroy_clusters.sh"
  echo ""
}

# ============================================
# MAIN
# ============================================

main() {
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸš€ CRÃ‰ATION DE L'INFRASTRUCTURE PAGERANK"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo ""
  
  # Ã‰tape 1: CrÃ©er le bucket
  create_bucket
  
  # Ã‰tape 2: CrÃ©er les 3 clusters
  echo "CrÃ©ation des clusters Dataproc..."
  echo "Cela peut prendre qlq minutes"
  echo ""
  
  # Configuration 1: 2 workers puissants
  create_cluster "pagerank-2w" 2 "n1-standard-8" "n1-standard-4"
  
  # Configuration 2: 4 workers moyens
  create_cluster "pagerank-4w" 4 "n1-standard-4" "n1-standard-4"
  
  # Configuration 3: 6 workers moyens
  create_cluster "pagerank-6w" 6 "n1-standard-4" "n1-standard-4"
  
  # Afficher le rÃ©sumÃ©
  show_info
}

# ============================================
# EXÃ‰CUTION
# ============================================

# Confirmation avant crÃ©ation
read -p "CrÃ©er 3 clusters Dataproc (coÃ»t ~$1-2/heure total)? [y/N] " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
  main
else
  echo "OpÃ©ration annulÃ©e"
  exit 0
fi